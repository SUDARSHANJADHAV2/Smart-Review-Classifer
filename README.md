# Review Classifier

## Description
This project is a Streamlit web application that classifies product reviews. It analyzes a given review text to predict its sentiment (Positive, Negative, Neutral), type (Query, Suggestion, Complaint, Feedback), and product category (based on underlying topics in the review text).

## Features
*   **Sentiment Analysis:** Predicts if a review expresses positive, negative, or neutral sentiment.
*   **Review Type Classification:** Categorizes the review as a general feedback, a query, a suggestion, or a complaint.
*   **Product Category Prediction:** Assigns the review to a relevant product category based on topic modeling.
*   **Advanced Analysis:**
    *   Provides matching keywords that contributed to the review type classification.
    *   Shows the cleaned text used for analysis.
    *   Displays information about the predicted product category, including its derived topic number.

## Models Used
*   **Sentiment Analysis:** Logistic Regression. The initial sentiment labels for training were likely derived using TextBlob's polarity scores (as seen in `project.ipynb`).
*   **Review Type Classification:** Multinomial Naive Bayes. This model is trained on text where types are determined by the presence of specific keywords.
*   **Product Category Prediction:** Random Forest Classifier. This model uses topics derived from Latent Dirichlet Allocation (LDA) as features to predict the category.

## Technology Stack
*   **Python 3.10**
*   **Streamlit:** For the web application interface.
*   **Pandas:** For data manipulation.
*   **Scikit-learn:** For machine learning models (Logistic Regression, Multinomial Naive Bayes, Random Forest, TF-IDF, LDA) and metrics.
*   **NLTK:** For natural language processing tasks (tokenization, stopwords, lemmatization).
*   **TextBlob:** Used for initial sentiment labeling in the training phase.
*   **Joblib:** For saving and loading trained models.
*   **Docker:** For containerizing the application.
*   **WordCloud:** For generating word clouds in the EDA phase (in `project.ipynb`).
*   **Matplotlib & Seaborn:** For plotting and visualizations in the EDA phase.

## Setup and Installation

### Prerequisites
*   Python 3.10 or higher
*   Docker (Optional, but recommended for easy deployment)
*   `pip` for installing Python packages

### Steps
1.  **Clone the repository:**
    ```bash
    git clone <your_repository_url>
    cd <repository_name>
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Download NLTK resources:**
    Run the following Python code (e.g., in a Python interpreter or add to a setup script):
    ```python
    import nltk
    nltk.download('stopwords')
    nltk.download('wordnet')
    nltk.download('omw-1.4')
    nltk.download('punkt')
    ```

## Running the Application

### 1. Using Streamlit (Locally)
Ensure all trained models are present in the `models/` directory. If not, you might need to run `project.ipynb` first (see Dataset and Model Training sections).

To start the Streamlit application:
```bash
streamlit run app.py
```
The application will typically be available at `http://localhost:8501` in your web browser.

### 2. Using Docker
This is a convenient way to run the application in a containerized environment.

1.  **Build the Docker image:**
    From the project root directory (where the `Dockerfile` is located):
    ```bash
    docker build -t review-classifier .
    ```

2.  **Run the Docker container:**
    ```bash
    docker run -p 8501:8501 review-classifier
    ```
    The application will be accessible at `http://localhost:8501`.

## Project Structure
```
.
├── .dockerignore
├── .gitattributes
├── Dockerfile            # Defines the Docker container for the app
├── README.md             # This file
├── app.py                # The main Streamlit application script
├── models/               # Directory containing pre-trained models
│   ├── department_model.pkl
│   ├── reviewtype_keywords.pkl
│   ├── reviewtype_model.pkl
│   ├── sentiment_model.pkl
│   ├── topic_category_mapping.pkl
│   └── vectorizer.pkl
├── project.ipynb         # Jupyter notebook for EDA, model training, and evaluation
├── requirements.txt      # Python dependencies
├── review_analysis.log   # Log file generated by the notebook
└── streamlit.pem         # (Likely a credential file, ensure it's handled securely or gitignored if sensitive)
```

## Dataset
The model training in `project.ipynb` uses the "Amazon Fine Food Reviews" dataset.
*   This dataset is **not included** in this repository due to its large size (typically >250MB).
*   To run the `project.ipynb` notebook for model retraining or exploration, you need to:
    1.  **Download the dataset:** A common source is Kaggle: [Amazon Fine Food Reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews) (You'll need `Reviews.csv`).
    2.  **Create a `data/` directory** at the root of this project.
    3.  **Place the `Reviews.csv` file** into this directory: `data/Reviews.csv`.

## Model Training (`project.ipynb`)
The `project.ipynb` Jupyter Notebook details the end-to-end process for training the models used in this application. Key steps include:

1.  **Exploratory Data Analysis (EDA):** Understanding the dataset, distributions of scores, review lengths, etc.
2.  **Text Preprocessing:**
    *   Lowercasing text.
    *   Removing URLs, mentions, hashtags, and special characters/punctuation.
    *   Tokenization.
    *   Stopword removal (using NLTK's English stopwords).
    *   Lemmatization (using NLTK's WordNetLemmatizer).
3.  **Sentiment Labeling:** Initial sentiment labels (Positive, Negative, Neutral) are generated for the training data using `TextBlob`'s sentiment polarity scores.
4.  **Review Type Labeling:** Review types (Query, Suggestion, Complaint, Feedback) are assigned based on the presence of predefined keywords in the cleaned text.
5.  **Product Category Modeling (LDA):**
    *   TF-IDF (Term Frequency-Inverse Document Frequency) vectorization is applied to the cleaned text.
    *   Latent Dirichlet Allocation (LDA) is used to identify 10 underlying topics from the TF-IDF features.
    *   These topics are manually mapped to product categories (e.g., "Pet Supplies", "Coffee & Pods").
6.  **Model Training and Evaluation:**
    *   **Sentiment Model:** A Logistic Regression classifier is trained on TF-IDF features of `CleanedText` to predict sentiment.
    *   **Review Type Model:** A Multinomial Naive Bayes classifier is trained on TF-IDF features of `CleanedText` to predict review type.
    *   **Product Category Model:** A Random Forest Classifier is trained on TF-IDF features of `CleanedText` to predict the LDA-derived topic, which is then mapped to a product category.
    *   All models are evaluated using classification reports and accuracy scores. Cross-validation is also performed for the sentiment model.
7.  **Saving Artifacts:**
    *   Trained models (`sentiment_model.pkl`, `reviewtype_model.pkl`, `department_model.pkl`) are saved using `joblib`.
    *   The TF-IDF `vectorizer.pkl` is saved.
    *   Mappings like `topic_category_mapping.pkl` and `reviewtype_keywords.pkl` are also saved.

## Future Improvements
*   **Hyperparameter Tuning:** Optimize models using techniques like GridSearchCV or RandomizedSearchCV.
*   **Advanced Feature Engineering:** Explore word embeddings (Word2Vec, GloVe, FastText) or transformer-based features (e.g., BERT embeddings).
*   **Experiment with Different Models:** Try other classification algorithms (e.g., SVM, Gradient Boosting, more advanced Deep Learning models for text).
*   **More Sophisticated Topic Modeling:** Use more advanced LDA variants or other topic modeling techniques.
*   **User Authentication:** Allow users to create accounts and save their review analysis history.
*   **Batch Analysis:** Allow uploading a CSV/text file for analyzing multiple reviews.
*   **Enhanced Error Handling & Logging:** Improve robustness in `app.py`.

## Contributing
Contributions are welcome! Please feel free to submit a pull request or open an issue for bugs, feature requests, or suggestions.
